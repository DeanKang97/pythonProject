from collections import Counter

import pandas as pd  # íŒë‹¤ìŠ¤
from konlpy.tag import *
from hanspell import spell_checker

import numpy as np

from nltk import FreqDist
# ì‹¤í–‰í–ˆì„ ë•Œ ì—ëŸ¬ ë©”ì‹œì§€ë¡œ punktì—ëŸ¬ ë‚˜ë©´ ë°‘ì— ëª…ë ¹ì–´ í•œë²ˆ ì‹¤í–‰
# nltk.download("punkt")


data = pd.read_csv('../TaeGeun/reviews.csv')  # ëŒ€ìƒ ë°ì´í„° ë¡œë”©

data = data.drop_duplicates(["content"], keep="last")

data["content"] = data["content"].str.lower()  # ì˜ì–´ëŠ” ì†Œë¬¸ìë¡œ í†µí•©

# # ì˜ì–´ë¥¼ í•œê¸€ë¡œ ë³€í™˜
# data["ë¦¬ë·°ë‚´ìš©"] = data["ë¦¬ë·°ë‚´ìš©"].str.replace("iphone", "ì•„ì´í°") \
#     .str.replace("black", "ë¸”ë™").str.replace("GB", "ê¸°ê°€")

hp = ''
for d in data['content']:  # ë¦¬ë·° í•˜ë‚˜ì˜ strë¡œ í•©
    hp += str(d)

spelled_sent = spell_checker.check(hp)
hp += spelled_sent.checked

okt = Okt()
print("----------using .morphs--------")

phr = okt.morphs(hp)  # Parse phrase to morphemes
print(phr)

noun = phr
#ë¶ˆìš©ì–´ ì œê±°
stopwords = ['ë­', 'ìœ¼ë©´', 'ì„', 'ì˜', 'ê°€', 'ì´', 'ì€', 'ë“¤', 'ëŠ”', 'ì¢€', 'ì˜', 'ê±', 'ê³¼', 'ë„', 'ë¥¼', 'ìœ¼ë¡œ',
             'ì', 'ì—', 'ì™€', 'í•œ', 'í•˜ë‹¤','.', 'ğŸ‘', '~', 'â™¥', '^^','ã…ã…']

arr = []
for i in range(0,len(noun)):
    if not noun[i] in stopwords:
        arr.append(noun[i])

count = Counter(arr)

for a,b in count.most_common(10):
    print(a)

